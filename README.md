# Репозиторий с итоговым проектом по дисциплине «Автоматизация процессов разработки и тестирования моделей машинного обучения»

[Ссылка на вторую часть проекта](https://github.com/Boryan71/MLOps_1)

В рамках задачи по автоматизации процесса разработки и обслуживания PD-модели реализован end-to-end автоматизированный пайплайн разработки, тестирования, сборки и мониторинга модели машинного обучения, предсказывающей вероятность дефолта клиента.

В рамках проекта реализованы: 
* контроль версий кода в [GitHub](https://github.com/Boryan71/MLOps),
* скрипты для [подготовки](./src/data/make_dataset.py) и [валидации данных](./src/data/validation.py) с использованием библиотеки GreatExpectations,
* [Sklearn Pipeline](./src/models/pipeline.py) для построения и настройки модели с автоматизированным подбором гиперпараметров с помощью библиотеки GridSearchCV,
* внедрен MLflow Tracking для записи и анализа различных сборок модели,
* для контроля версий данных и моделей огранизован [DVC-пайплайн](./dvc.yaml),
* настроен [CI-пайплайн](./.github/workflows/ci_cd.yml) в GitHub Actions, включающий в себя проверку форматирования и линтинга с помощью библиотек black и flake8, а также проверка входных данных с помощью набора правил GreatExpectations,
* реализована [контейнеризация приложения](./Dockerfile) в Docker c возможностью обращения к обученной модели по REST API, для получения предсказания о вероятности дефолта клиента,
* отдельным [скриптом](./tests/monitoring/cd_monitoring.py) реализован мониторинг дрифта обучающих данных, переподнимающий Docker-контейнер с моделью при значительных изменениях метрики PSI. 

## Инструкция по запуску  
1. Клонируем репозиторий:  
```bash
git clone https://github.com/Boryan71/MLOps.git
```  
2. Вызываем запуск DVC-пайплайна для валидации данных и контроля выполнения всех шагов:  
``` bash
dvc repro -f
```  
3. При успешном прохождении всех проверок - поднимаем Docker-контейнер с обученной моделью:  
``` bash
# Для первого запуска и проверки или перестройки приложения при внесении изменений 
docker-compose up --build

# Тихий режим
docker-compose up -d
```  
4. Передаем в контейнер с моделью [.json-файл](./data/tests/example.json) с данными для предсказания вероятности дефолта клиентов:  
```bash
curl -X POST http://127.0.0.1:8000/predict/ -H "Content-Type: application/json" -d @./data/tests/example.json
```  

В результате должны иметь работающий Docker-контейнер с обученной моделью предсказания вероятности дефолта клиента:
![docker](./readme/docker.png)
![predict](./readme/predict.png)

5. Отдельным [скриптом](./tests/monitoring/cd_monitoring.py) реализован мониторинг дрифта данных по метрике PSI, имитирующий поступление новых данных, переобучающий и переподнимающий модель при значительном отклонении.
Вызов:
``` bash
python src/features/cd_monitoring.py 
```

## Обзор реализованных функций
### Валидация данных при помощи GreatExpectations
Для валидации входных данных реализован набор правил GreatExpectations в скрипте [validation.py](./src/data/validation.py).

### Построение и автоматизированная настройка модели через Sklearn Pipeline с подключенным логированием MLflow Tracking
Создание модели выполнено в виде пайплайна Sklearn Pipeline, который включает в себя этапы предобработки и обучения.  
Для логирования метрик модели используется MLflow Tracking, а также сохранение данных в JSON-файл.  
Данный шаг организован в скрипте [pipeline.py](./src/models/pipeline.py)

### DVC-пайплайн
Для автоматизированного контроля данных и моделей, а также учета зависимостей выполнения python-скриптов, реализован [DVC-пайплайн](./dvc.yaml).

Для запуска пайплайна в корне проекта используется команда:  
 
``` bash
dvc repro
```

![dvc repro](./readme/dvc_repro.png)

### GitHub Actions
При пуше изменений в репозиторий запускается CI-пайплайн проверки с помощью [GitHub Actions](./.github/workflows/ci_cd.yml).  
Внутри пайплайна реализованы проверки линтинга с помощью flake8 и форматирования основных python-скриптов с помощью black, а также валидация тестовых данных с помощью набора правил GreatExpectations

Для ручной проверки необходимо вызвать из корня проекта следующие команды:

``` bash
flake8 --max-line-length=125 src
black --check src
```

### Контейнеризация приложения в Docker и вызов модели по REST API
Готовый проект упаковывается в Docker-контейнер. Настройки контейнеризации указаны в [Dockerfile](./Dockerfile) и [docker-compose](./docker-compose.yml).  
Контейнер считается запущенным при наличии в консоли следующей строки:

``` bash
app-1  | INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

При помощи фреймворка [FastAPI](./src/api/app.py) реализована возможность получения предсказаний через POST-запрос к контейнеру с предоставлением данных о клиенте.  
Пример запроса из CMD (Windows):

``` bash
curl -X POST http://127.0.0.1:8000/predict/ -H "Content-Type: application/json" -d @./data/tests/example.json
```
